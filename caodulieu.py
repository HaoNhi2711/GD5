import os
import requests
from bs4 import BeautifulSoup

# URL trang c·∫ßn c√†o d·ªØ li·ªáu
URL = "https://www.vinmec.com/vie/bai-viet/nguyen-nhan-benh-u-lympho-ac-tinh-khong-hodgkin-vi"

# Th∆∞ m·ª•c l∆∞u d·ªØ li·ªáu
SAVE_DIR = "D:/ChatBotThucTap/demo/data_in"
os.makedirs(SAVE_DIR, exist_ok=True)

# T√™n file TXT ƒë·ªÉ l∆∞u n·ªôi dung
FILENAME = os.path.join(SAVE_DIR, "u_lympho_ac_tinh.txt")

def scrape_and_save(url, filename):
    """C√†o d·ªØ li·ªáu t·ª´ trang web v√† l∆∞u v√†o file TXT k√®m link b√†i vi·∫øt"""
    try:
        # G·ª≠i y√™u c·∫ßu HTTP ƒë·∫øn trang web
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/134.0.0.0 Safari/537.36"
        }
        response = requests.get(url, headers=headers)
        response.raise_for_status()  # Ki·ªÉm tra l·ªói HTTP

        # Ph√¢n t√≠ch HTML b·∫±ng BeautifulSoup
        soup = BeautifulSoup(response.text, "lxml")

        # L·∫•y n·ªôi dung t·ª´ th·∫ª ch·ª©a b√†i vi·∫øt
        paragraphs = soup.find_all("p")  # N·∫øu trang web d√πng th·∫ª kh√°c, c·∫ßn ƒëi·ªÅu ch·ªânh

        # Tr√≠ch xu·∫•t n·ªôi dung v√† n·ªëi l·∫°i th√†nh vƒÉn b·∫£n
        content = "\n".join([p.text.strip() for p in paragraphs if p.text.strip()])

        if not content:
            raise ValueError("Kh√¥ng t√¨m th·∫•y n·ªôi dung b√†i vi·∫øt!")

        # Th√™m link b√†i vi·∫øt v√†o n·ªôi dung
        full_content = f"üîó Link b√†i vi·∫øt: {url}\n\n{content}"

        # L∆∞u n·ªôi dung v√†o file TXT
        with open(filename, "w", encoding="utf-8") as file:
            file.write(full_content)

        print(f"‚úÖ ƒê√£ l∆∞u d·ªØ li·ªáu v√†o {filename}")

    except requests.exceptions.RequestException as e:
        print(f"‚ùå L·ªói khi t·∫£i trang web: {e}")
    except Exception as e:
        print(f"‚ùå L·ªói khi x·ª≠ l√Ω d·ªØ li·ªáu: {e}")

# Ch·∫°y c√†o d·ªØ li·ªáu
scrape_and_save(URL, FILENAME)